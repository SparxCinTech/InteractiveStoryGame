models:
  llama-lmstudio:
    base_url: http://localhost:1234/v1
    context_window: 8192
    extra_params:
      frequency_penalty: 0.1
      presence_penalty: 0.1
    max_tokens: 2048
    model_name: llama-3.1-8b-lexi-uncensored-v2
    provider: lmstudio
    stop:
    - 'Human:'
    - 'Assistant:'
    temperature: 0.8
    top_p: 0.9
  mistral-ollama:
    base_url: http://localhost:11434
    context_window: 4096
    default: true
    extra_params:
      num_predict: 2048
    max_tokens: 2048
    model_name: mistral
    num_gpu: 1
    provider: ollama
    repeat_penalty: 1.1
    stop:
    - 'Human:'
    - 'Assistant:'
    temperature: 0.7
    top_p: 0.9
